{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"11bUaqvUj0R9r8i60ObIYMrA_OdyfVp61","timestamp":1736573234280}],"authorship_tag":"ABX9TyOcquXiBup2AyDeZnePjA+b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["TASK 3: TEXT GENERATION WITH MARCOV CHAINS"],"metadata":{"id":"_nV3KzQW00QY"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yh-5aKGs0Sme","executionInfo":{"status":"ok","timestamp":1736573020304,"user_tz":-330,"elapsed":454,"user":{"displayName":"Srijan Roy","userId":"15062122145989637074"}},"outputId":"699556fa-359c-41e2-f6b0-aca379af3129"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Text:\n","The fox is clever and quick.\n"]}],"source":["import random\n","from collections import defaultdict\n","\n","\n","class MarkovChainTextGenerator:\n","    def __init__(self):\n","        self.model = defaultdict(list)\n","\n","    def train(self, text, n=1):\n","        \"\"\"\n","        Train the Markov chain model on a given text.\n","\n","        :param text: Input text for training.\n","        :param n: Order of the Markov chain (number of previous words to consider).\n","        \"\"\"\n","        words = text.split()\n","        for i in range(len(words) - n):\n","            key = tuple(words[i:i + n])\n","            next_word = words[i + n]\n","            self.model[key].append(next_word)\n","\n","    def generate(self, length=20, seed=None):\n","        \"\"\"\n","        Generate text using the trained Markov chain model.\n","\n","        :param length: Number of words to generate.\n","        :param seed: Starting word(s) as a tuple. If None, a random seed is chosen.\n","        :return: Generated text as a string.\n","        \"\"\"\n","        if not self.model:\n","            raise ValueError(\"The model is empty. Train the model first.\")\n","\n","        # Choose a random starting point if no seed is provided\n","        seed = seed or random.choice(list(self.model.keys()))\n","        output = list(seed)\n","\n","        for _ in range(length - len(seed)):\n","            current_state = tuple(output[-len(seed):])\n","            next_words = self.model.get(current_state, None)\n","            if not next_words:\n","                break\n","            next_word = random.choice(next_words)\n","            output.append(next_word)\n","\n","        return \" \".join(output)\n","\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    # Input text\n","    training_text = \"\"\"\n","    The quick brown fox jumps over the lazy dog. The fox is clever and quick.\n","    \"\"\"\n","\n","    # Create and train the Markov chain model\n","    markov = MarkovChainTextGenerator()\n","    markov.train(training_text, n=2)  # Train with bigrams (n=2)\n","\n","    # Generate text\n","    generated_text = markov.generate(length=20)\n","    print(\"Generated Text:\")\n","    print(generated_text)\n"]},{"cell_type":"code","source":["import random\n","from collections import defaultdict\n","\n","class MarkovChainTextGenerator:\n","    def __init__(self):\n","        self.model = defaultdict(list)\n","\n","    def train(self, text, n=1):\n","        \"\"\"\n","        Train the Markov chain model on a given text.\n","\n","        :param text: Input text for training.\n","        :param n: Order of the Markov chain (number of previous words to consider).\n","        \"\"\"\n","        words = text.split()\n","        for i in range(len(words) - n):\n","            key = tuple(words[i:i + n])\n","            next_word = words[i + n]\n","            self.model[key].append(next_word)\n","\n","    def generate(self, length=20, seed=None):\n","        \"\"\"\n","        Generate text using the trained Markov chain model.\n","\n","        :param length: Number of words to generate.\n","        :param seed: Starting word(s) as a tuple. If None, a random seed is chosen.\n","        :return: Generated text as a string.\n","        \"\"\"\n","        if not self.model:\n","            raise ValueError(\"The model is empty. Train the model first.\")\n","\n","        # Choose a random starting point if no seed is provided\n","        seed = seed or random.choice(list(self.model.keys()))\n","        output = list(seed)\n","\n","        for _ in range(length - len(seed)):\n","            current_state = tuple(output[-len(seed):])\n","            next_words = self.model.get(current_state, None)\n","            if not next_words:\n","                break\n","            next_word = random.choice(next_words)\n","            output.append(next_word)\n","\n","        return \" \".join(output)\n","\n","\n","# Example Usage\n","if __name__ == \"__main__\":\n","    # Training text\n","    training_text = \"\"\"\n","    It was a bright cold day in April, and the clocks were striking thirteen.\n","    Winston Smith slipped quickly through the glass doors of Victory Mansions,\n","    though not quickly enough to prevent a swirl of gritty dust from entering along with him.\n","    \"\"\"\n","\n","    # Initialize and train the Markov Chain Text Generator\n","    markov = MarkovChainTextGenerator()\n","    markov.train(training_text, n=2)  # Train with bigrams (n=2)\n","\n","    # Generate text\n","    generated_text = markov.generate(length=50)\n","    print(\"Generated Text:\")\n","    print(generated_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yH5kr8eb0t5H","executionInfo":{"status":"ok","timestamp":1736573125779,"user_tz":-330,"elapsed":461,"user":{"displayName":"Srijan Roy","userId":"15062122145989637074"}},"outputId":"14266d44-6f69-44ce-84ba-6b09a13e1961"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Text:\n","of Victory Mansions, though not quickly enough to prevent a swirl of gritty dust from entering along with him.\n"]}]}]}